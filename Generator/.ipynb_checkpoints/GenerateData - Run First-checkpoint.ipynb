{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"loan_amnt\", \"int_rate\", \"installment\", \"home_ownership\", \"annual_inc\", \n",
    "    \"verification_status\", \"pymnt_plan\", \"dti\", \"delinq_2yrs\", \n",
    "    \"inq_last_6mths\", \"open_acc\", \"pub_rec\", \"revol_bal\", \"total_acc\", \n",
    "    \"initial_list_status\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\", \n",
    "    \"total_pymnt_inv\", \"total_rec_prncp\", \"total_rec_int\", \n",
    "    \"total_rec_late_fee\", \"recoveries\", \"collection_recovery_fee\", \n",
    "    \"last_pymnt_amnt\", \"collections_12_mths_ex_med\", \"policy_code\", \n",
    "    \"application_type\", \"acc_now_delinq\", \"tot_coll_amt\", \"tot_cur_bal\", \n",
    "    \"open_acc_6m\", \"open_act_il\", \"open_il_12m\", \"open_il_24m\", \n",
    "    \"mths_since_rcnt_il\", \"total_bal_il\", \"il_util\", \"open_rv_12m\", \n",
    "    \"open_rv_24m\", \"max_bal_bc\", \"all_util\", \"total_rev_hi_lim\", \"inq_fi\", \n",
    "    \"total_cu_tl\", \"inq_last_12m\", \"acc_open_past_24mths\", \"avg_cur_bal\", \n",
    "    \"bc_open_to_buy\", \"bc_util\", \"chargeoff_within_12_mths\", \"delinq_amnt\", \n",
    "    \"mo_sin_old_il_acct\", \"mo_sin_old_rev_tl_op\", \"mo_sin_rcnt_rev_tl_op\", \n",
    "    \"mo_sin_rcnt_tl\", \"mort_acc\", \"mths_since_recent_bc\", \n",
    "    \"mths_since_recent_inq\", \"num_accts_ever_120_pd\", \"num_actv_bc_tl\",\n",
    "    \"num_actv_rev_tl\", \"num_bc_sats\", \"num_bc_tl\", \"num_il_tl\", \n",
    "    \"num_op_rev_tl\", \"num_rev_accts\", \"num_rev_tl_bal_gt_0\", \"num_sats\", \n",
    "    \"num_tl_120dpd_2m\", \"num_tl_30dpd\", \"num_tl_90g_dpd_24m\", \n",
    "    \"num_tl_op_past_12m\", \"pct_tl_nvr_dlq\", \"percent_bc_gt_75\", \n",
    "    \"pub_rec_bankruptcies\", \"tax_liens\", \"tot_hi_cred_lim\", \n",
    "    \"total_bal_ex_mort\", \"total_bc_limit\", \"total_il_high_credit_limit\", \n",
    "    \"hardship_flag\", \"debt_settlement_flag\",\n",
    "    \"loan_status\"\n",
    "]\n",
    "\n",
    "target = \"loan_status\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df1 = pd.read_csv(Path('LoanStats_2019Q1.csv.zip'), skiprows=1)[:-2]\n",
    "df2 = pd.read_csv(Path('LoanStats_2019Q2.csv.zip'), skiprows=1)[:-2]\n",
    "df3 = pd.read_csv(Path('LoanStats_2019Q3.csv.zip'), skiprows=1)[:-2]\n",
    "df4 = pd.read_csv(Path('LoanStats_2019Q4.csv.zip'), skiprows=1)[:-2]\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4]).loc[:, columns].copy()\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove the `Issued` loan status\n",
    "issued_mask = df['loan_status'] != 'Issued'\n",
    "df = df.loc[issued_mask]\n",
    "\n",
    "# convert interest rate to numerical\n",
    "df['int_rate'] = df['int_rate'].str.replace('%', '')\n",
    "df['int_rate'] = df['int_rate'].astype('float') / 100\n",
    "\n",
    "\n",
    "# Convert the target column values to low_risk and high_risk based on their values\n",
    "x = {'Current': 'low_risk'}   \n",
    "df = df.replace(x)\n",
    "\n",
    "x = dict.fromkeys(['Late (31-120 days)', 'Late (16-30 days)', 'Default', 'In Grace Period'], 'high_risk')    \n",
    "df = df.replace(x)\n",
    "\n",
    "\n",
    "low_risk_rows = df[df[target] == 'low_risk']\n",
    "high_risk_rows = df[df[target] == 'high_risk']\n",
    "\n",
    "#df = pd.concat([low_risk_rows, high_risk_rows.sample(n=len(low_risk_rows), replace=True)])\n",
    "df = pd.concat([low_risk_rows.sample(n=len(high_risk_rows), random_state=42), high_risk_rows])\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.rename({target:'target'}, axis=\"columns\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('2019loans.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "validate_df = pd.read_csv(Path('LoanStats_2020Q1.csv.zip'), skiprows=1)[:-2]\n",
    "validate_df = validate_df.loc[:, columns].copy()\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "validate_df = validate_df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "validate_df = validate_df.dropna()\n",
    "\n",
    "# Remove the `Issued` loan status\n",
    "issued_mask = validate_df[target] != 'Issued'\n",
    "validate_df = validate_df.loc[issued_mask]\n",
    "\n",
    "# convert interest rate to numerical\n",
    "validate_df['int_rate'] = validate_df['int_rate'].str.replace('%', '')\n",
    "validate_df['int_rate'] = validate_df['int_rate'].astype('float') / 100\n",
    "\n",
    "\n",
    "# Convert the target column values to low_risk and high_risk based on their values\n",
    "x = dict.fromkeys(['Current', 'Fully Paid'], 'low_risk') \n",
    "validate_df = validate_df.replace(x)\n",
    "\n",
    "x = dict.fromkeys(['Late (31-120 days)', 'Late (16-30 days)', 'Default', 'In Grace Period', 'Charged Off'], 'high_risk')    \n",
    "validate_df = validate_df.replace(x)\n",
    "\n",
    "low_risk_rows = validate_df[validate_df[target] == 'low_risk']\n",
    "high_risk_rows = validate_df[validate_df[target] == 'high_risk']\n",
    "\n",
    "validate_df = pd.concat([low_risk_rows.sample(n=len(high_risk_rows), random_state=37), high_risk_rows])\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "validate_df = validate_df.rename({target:'target'}, axis=\"columns\")\n",
    "validate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df.to_csv('2020Q1loans.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
